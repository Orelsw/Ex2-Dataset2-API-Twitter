---
title: "Twitter API - Superclásico"
output: html_document
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 200)
```
___
#### *Authors:* Ronit Yoari & Orel Swisa  
#### *Date*: April 13, 2016  
#### *The API Dataset based [Twitter](https://twitter.com) - Connect Orel_Swisa Twitter account *   
___
### *Data Description*
- This report provide detailed **hashtag** data from twitter about the **Superclásico - Real Madrid VS Barcelona** football match, which took place on April 2, 2016.  
- The statistics relate only to tweets that contain the **Superclásico** hashtag.  

___
### *Data Example - Reading first data records*
```{r,echo=FALSE,message=FALSE, warning=FALSE}
library(tm)
library(twitteR)

# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"

# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)

folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
  # get 500 tweets with the hashtag #SuperClasico
  SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
  save(SuperClasico, file=folder, compress=TRUE)
} else{
  load(folder)
}

head(SuperClasico)

# Get the Date
dateAPI <- date()
dateAPI
```
___
### *Summary*  
#### *Some statistics on the tweets with **Superclásico** hashtag.*  
```{r,echo=FALSE,message=FALSE}
# Summarize information about a list of tweets in a data frame - SuperClasico.
data_mining_SuperClasico <- twListToDF(SuperClasico)

# Remove stop words :
data_mining_SuperClasico2 = stringr::str_replace_all(data_mining_SuperClasico$text,"[^[:graph:]]", " ")

# get the body of SuperClasico hashtag
data_mining_corpus_SuperClasico = tm::Corpus(VectorSource(data_mining_SuperClasico2))

# remove stripWhitespace from text.
# get the text in lower case.
# remove Punctuation from text.
# remove not english words.
# ADD : Document To term
data_mining_tdm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 1, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))

# Rows = Terms
# Cols = Document
# matrix with all data
m <- as.matrix(data_mining_tdm)
```

- Most frequently used words in tweets with hashtag #SuperClasico:  
```{r,echo=FALSE,message=FALSE}
word_freqs <- sort(rowSums(m), decreasing = TRUE)
head(word_freqs)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
```

- Sum of tweets with hashtag #SuperClasico that contains the word ***Real Madrid*** (ignore lowwer/uper case):  
```{r,echo=FALSE,message=FALSE}
num<-length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-num+length(grep('RealMadrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num
```

- Sum of tweets with hashtag #SuperClasico that contains the word ***Barcelona*** (ignore lowwer/uper case)
```{r,echo=FALSE,message=FALSE}
length(grep('Barcelona',data_mining_SuperClasico$text, ignore.case = TRUE))
```
___
### *Wordcloud of tweets use with hashtag **#SuperClasico***  
```{r,echo=FALSE,message=FALSE}
library(wordcloud)
wordcloud(head(dm$word,200), head(dm$freq,200), random.order = FALSE, colors = brewer.pal(8, 'Dark2'), max.words = 100)
```
  
#### ***Wordcloud Conclusions:***  
As we can see from the wordcloud, the words with the greatest number of occurrences in the sample tweets are:  
- **Superclásico**.  
- **RealMadrid**.  
- **Barcelona**.

In that Superclásico, **Real Madrid beat Barcelona 2-1**, hence Real Madrid's fans were more proud, and due to they tweeted more.  
More than that, as we can see acording to the wordcloud, the word **Cristiano** - that represented Real Madrid's player "Cristiano Ronaldo", is also have a big number of occurrences in the sample tweets. It resulted because he scored the winning goal in that match, that brought the victory to Real Madrid.  

___  
### *Network analysis of tweets that contain the hashtag **Superclásico***  
#### Containing the following words:  
- ***Barcelona's players*** : Messi, Neymar, Luis Suarez  
**MSN** = **M**essi, **S**uarez, **N**eymar.
- ***Real Madrid's players*** : Cristiano Ronaldo, Gareth Bale, Karim Benzema  
**BBC** = **B**ale, **B**enzema, **C**ristiano  
```{r,echo=FALSE,message=FALSE,include=FALSE}
superclassico_dtm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 4, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
te<-inspect(superclassico_dtm)
termsMet <- te %*% t(te)
```
```{r,echo=FALSE,message=FALSE}
library(igraph)

terms<-c('superclasico','realmadrid','barcelona','messi','neymar','suarez','cristiano','bale','benzema','bbc','msn')
termsMet<-termsMet[terms,terms]
termsMet

g <- graph.adjacency(termsMet, weighted=TRUE, mode = 'undirecte')
g <- set.edge.attribute(g, "weight", value=runif(ecount(g)))
g <- simplify(g)
V(g)$color <- "seagreen1"
V(g)$label <- V(g)$name
V(g)$degree <- degree(g)

# set seed to make the layout reproducible
set.seed(2000)
layout1 <- layout.fruchterman.reingold(g)

V(g)$label.cex <- 2.2 * V(g)$degree / max(V(g)$degree)+ .2
V(g)$label.color <- rgb(0, 0, .2, .8)
V(g)$frame.color <- NA

# plot the graph in layout1
plot(g, layout=layout1,vertex.size=30)
```
  
___   
### *The graph below shows the **frequency** of tweets with #Superclásico*  
### *durring the week of the Superclásico* 
```{r,echo=FALSE,message=FALSE, warning=FALSE}
library(ggplot2)

tweets <- list()
dates <- paste("2016-04-",01:05,sep="")
for (i in 2:length(dates)) {
  tweets <- c(tweets, searchTwitter("#Superclásico", since=dates[i-1], until=dates[i], n=1500))
}

# Convert the list to a data frame
tweets <- twListToDF(tweets)
tweets <- unique(tweets)

# To ensure accuracy, make sure that there were no more than 1500 tweets in a single day.
# If there are 1500 on any single day, then you're truncating that day's tweets, and you'll
# need to try to get ROAuth (below) working.
tweets$date <- format(tweets$created, format="%Y-%m-%d")
table(tweets$date)

# @sciencestream is a spambot that's RT'ing everything on the #ISMB tag. Get rid of those.
tweets <- tweets[which(tweets$screenName!="sciencestream"), ]

# Make a table of the number of tweets per user
d <- as.data.frame(table(tweets$screenName))
d <- d[order(d$Freq, decreasing=T), ]
names(d) <- c("User","Tweets")
head(d)

# Plot the table above for the top 40
png("Superclásico-users.png", w=700, h=1000)
par(mar=c(5,10,2,2))
with(d[rev(1:40), ], barplot(Tweets, names=User, horiz=T, las=1, main="Top 40: Tweets per User", col=1))
dev.off()

# Plot the frequency of tweets over time in two hour windows
# Modified from http://michaelbommarito.com/2011/03/12/a-quick-look-at-march11-saudi-tweets/
minutes <- 120
ggplot(data=tweets, aes(x=created)) + 
  geom_bar(aes(fill=..count..), binwidth=60*minutes) + 
  scale_x_datetime("Date") + 
  scale_y_continuous("Frequency")

ggsave(file='Superclásico-Frequency.png', width=7, height=7, dpi=100)
```
  
___
### *Summary, Conclusions and Recommendations for Further Research.*
In conclusion, this report shows that can we link between terms, in the context of social networks posts, like Twitter.
We can analyze **trends** according to the **time and content** of posts on the social networks in extensive and varied issues, - in particular in sports as demonstrated in the above report
  
Our recommendation for further research, is to cross-check between more than one issues, to see if there is a common ground between them.