setwd("~/Google Drive/DataScientist/Ass2/Dataset2_API")
install.packages("tm")
install.packages("twitteR")
install.packages("wordcloud")
install.packages("igraph")
library(tm)
library(twitteR)
dateAPI <- date()
dateAPI
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
help("save")
saveRDS(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
setwd("~/Google Drive/DataScientist/Ass2/Dataset2_API")
saveRDS(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
saveRDS(SuperClasico, file="SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file="data\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file=".\data\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file=".\\data\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file=".\\data\\SuperClasico.Rdata.gz", compress=TRUE)
save(SuperClasico, file="SuperClasico.Rdata.gz", compress=TRUE)
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
SuperClasico<-load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
head(SuperClasico)
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
# Chunk 1: set-options
options(width = 200)
# Chunk 2
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
# Chunk 3
# Summarize information about a list of tweets in a data frame - SuperClasico.
data_mining_SuperClasico <- twListToDF(SuperClasico)
# Remove stop words :
data_mining_SuperClasico2 = stringr::str_replace_all(data_mining_SuperClasico$text,"[^[:graph:]]", " ")
# get the body of SuperClasico hashtag
data_mining_corpus_SuperClasico = tm::Corpus(VectorSource(data_mining_SuperClasico2))
# remove stripWhitespace from text.
# get the text in lower case.
# remove Punctuation from text.
# remove not english words.
# ADD : Document To term
data_mining_tdm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 1, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
# Rows = Terms
# Cols = Document
# matrix with all data
m <- as.matrix(data_mining_tdm)
# Chunk 4
word_freqs <- sort(rowSums(m), decreasing = TRUE)
head(word_freqs)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-num+length(grep('RealMadrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num
#### ***Wordcloud Conclusions:***
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
termsMet <- te %*% t(te)
# Chunk 1: set-options
options(width = 200)
# Chunk 2
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
# Chunk 3
# Summarize information about a list of tweets in a data frame - SuperClasico.
data_mining_SuperClasico <- twListToDF(SuperClasico)
# Remove stop words :
data_mining_SuperClasico2 = stringr::str_replace_all(data_mining_SuperClasico$text,"[^[:graph:]]", " ")
# get the body of SuperClasico hashtag
data_mining_corpus_SuperClasico = tm::Corpus(VectorSource(data_mining_SuperClasico2))
# remove stripWhitespace from text.
# get the text in lower case.
# remove Punctuation from text.
# remove not english words.
# ADD : Document To term
data_mining_tdm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 1, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
# Rows = Terms
# Cols = Document
# matrix with all data
m <- as.matrix(data_mining_tdm)
# Chunk 4
word_freqs <- sort(rowSums(m), decreasing = TRUE)
head(word_freqs)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
# Chunk 5
num<-length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-num+length(grep('RealMadrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num
# Chunk 6
length(grep('Barcelona',data_mining_SuperClasico$text, ignore.case = TRUE))
# Chunk 7
library(wordcloud)
wordcloud(head(dm$word,200), head(dm$freq,200), random.order = FALSE, colors = brewer.pal(8, 'Dark2'), max.words = 100)
#       user <- twitteR::getUser('Orel_Swisa')
#       friends <- user$getFriends()
#       friends
n<-20
name<-"Orel_Swisa"
#       friends <- sapply(friends.object[1:n],name)
#       followers <- sapply(followers.object[1:n],name)
superclassico_dtm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 4, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
#       View(inspect(superclasico_dtm))
te<-inspect(superclassico_dtm)
termsMet <- te %*% t(te)
# Chunk 1: set-options
options(width = 200)
# Chunk 2
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
# Chunk 3
# Summarize information about a list of tweets in a data frame - SuperClasico.
data_mining_SuperClasico <- twListToDF(SuperClasico)
# Remove stop words :
data_mining_SuperClasico2 = stringr::str_replace_all(data_mining_SuperClasico$text,"[^[:graph:]]", " ")
# get the body of SuperClasico hashtag
data_mining_corpus_SuperClasico = tm::Corpus(VectorSource(data_mining_SuperClasico2))
# remove stripWhitespace from text.
# get the text in lower case.
# remove Punctuation from text.
# remove not english words.
# ADD : Document To term
data_mining_tdm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 1, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
# Rows = Terms
# Cols = Document
# matrix with all data
m <- as.matrix(data_mining_tdm)
# Chunk 4
word_freqs <- sort(rowSums(m), decreasing = TRUE)
head(word_freqs)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
# Chunk 5
num<-length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-num+length(grep('RealMadrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num
# Chunk 6
length(grep('Barcelona',data_mining_SuperClasico$text, ignore.case = TRUE))
# Chunk 7
library(wordcloud)
wordcloud(head(dm$word,200), head(dm$freq,200), random.order = FALSE, colors = brewer.pal(8, 'Dark2'), max.words = 100)
# Chunk 1: set-options
options(width = 200)
# Chunk 2
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
# Chunk 3
# Summarize information about a list of tweets in a data frame - SuperClasico.
data_mining_SuperClasico <- twListToDF(SuperClasico)
# Remove stop words :
data_mining_SuperClasico2 = stringr::str_replace_all(data_mining_SuperClasico$text,"[^[:graph:]]", " ")
# get the body of SuperClasico hashtag
data_mining_corpus_SuperClasico = tm::Corpus(VectorSource(data_mining_SuperClasico2))
# remove stripWhitespace from text.
# get the text in lower case.
# remove Punctuation from text.
# remove not english words.
# ADD : Document To term
data_mining_tdm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 1, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
# Rows = Terms
# Cols = Document
# matrix with all data
m <- as.matrix(data_mining_tdm)
# Chunk 4
word_freqs <- sort(rowSums(m), decreasing = TRUE)
head(word_freqs)
dm <- data.frame(word=names(word_freqs), freq=word_freqs)
# Chunk 5
num<-length(grep('Real Madrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num<-num+length(grep('RealMadrid',data_mining_SuperClasico$text, ignore.case = TRUE))
num
# Chunk 6
length(grep('Barcelona',data_mining_SuperClasico$text, ignore.case = TRUE))
# Chunk 7
library(wordcloud)
wordcloud(head(dm$word,200), head(dm$freq,200), random.order = FALSE, colors = brewer.pal(8, 'Dark2'), max.words = 100)
superclassico_dtm = TermDocumentMatrix(data_mining_corpus_SuperClasico, control = list(minWordLength = 4, removePunctuation=TRUE, stopwords = c(stopwords('english')), removeNumbers=TRUE,tolower=TRUE,stripWhitespace=TRUE))
te<-inspect(superclassico_dtm)
termsMet <- te %*% t(te)
termsMet
install.packages("tcltk2")
install.packages("InteractiveIGraph")
install.packages("tkrplot")
help("plot")
g$layout<-layout.circle(g)
plot(g)
SuperClasico1 <- searchTwitter("#SuperClasico" ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
length(SuperClasico1)
SuperClasico1 <- searchTwitter("#SuperClasico" ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
SuperClasico1
SuperClasico1 <- searchTwitter("#Superclásico" ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
SuperClasico1
dates <- paste("2016-04-",01:05,sep="") # need to go to 18th to catch tweets from 17th
dates
library(twitteR)
library(ggplot2)
tweets <- list()
dates <- paste("2016-04-",01:05,sep="") # need to go to 18th to catch tweets from 17th
for (i in 2:length(dates)) {
print(paste(dates[i-1], dates[i]))
tweets <- c(tweets, searchTwitter("#Superclásico", since=dates[i-1], until=dates[i], n=1500))
}
# Convert the list to a data frame
tweets <- twListToDF(tweets)
tweets <- unique(tweets)
# To ensure accuracy, make sure that there were no more than 1500 tweets in a single day.
# If there are 1500 on any single day, then you're truncating that day's tweets, and you'll
# need to try to get ROAuth (below) working.
tweets$date <- format(tweets$created, format="%Y-%m-%d")
table(tweets$date)
# @sciencestream is a spambot that's RT'ing everything on the #ISMB tag. Get rid of those.
tweets <- tweets[which(tweets$screenName!="sciencestream"), ]
# Make a table of the number of tweets per user
d <- as.data.frame(table(tweets$screenName))
d <- d[order(d$Freq, decreasing=T), ]
names(d) <- c("User","Tweets")
head(d)
# Plot the table above for the top 40
png("ismb-users.png", w=700, h=1000)
par(mar=c(5,10,2,2))
with(d[rev(1:40), ], barplot(Tweets, names=User, horiz=T, las=1, main="Top 40: Tweets per User", col=1))
dev.off()
# Plot the frequency of tweets over time in two hour windows
# Modified from http://michaelbommarito.com/2011/03/12/a-quick-look-at-march11-saudi-tweets/
minutes <- 120
ggplot(data=tweets, aes(x=created)) +
geom_bar(aes(fill=..count..), binwidth=60*minutes) +
scale_x_datetime("Date") +
scale_y_continuous("Frequency") +
opts(title="#Superclásico Tweet Frequency April 1-5", legend.position='none')
ggsave(file='ismb-frequency.png', width=7, height=7, dpi=100)
library(twitteR)
library(ggplot2)
tweets <- list()
dates <- paste("2016-04-",01:05,sep="") # need to go to 18th to catch tweets from 17th
for (i in 2:length(dates)) {
print(paste(dates[i-1], dates[i]))
tweets <- c(tweets, searchTwitter("#Superclásico", since=dates[i-1], until=dates[i], n=1500))
}
# Convert the list to a data frame
tweets <- twListToDF(tweets)
tweets <- unique(tweets)
# To ensure accuracy, make sure that there were no more than 1500 tweets in a single day.
# If there are 1500 on any single day, then you're truncating that day's tweets, and you'll
# need to try to get ROAuth (below) working.
tweets$date <- format(tweets$created, format="%Y-%m-%d")
table(tweets$date)
# @sciencestream is a spambot that's RT'ing everything on the #ISMB tag. Get rid of those.
tweets <- tweets[which(tweets$screenName!="sciencestream"), ]
# Make a table of the number of tweets per user
d <- as.data.frame(table(tweets$screenName))
d <- d[order(d$Freq, decreasing=T), ]
names(d) <- c("User","Tweets")
head(d)
# Plot the table above for the top 40
png("ismb-users.png", w=700, h=1000)
par(mar=c(5,10,2,2))
with(d[rev(1:40), ], barplot(Tweets, names=User, horiz=T, las=1, main="Top 40: Tweets per User", col=1))
dev.off()
# Plot the frequency of tweets over time in two hour windows
# Modified from http://michaelbommarito.com/2011/03/12/a-quick-look-at-march11-saudi-tweets/
minutes <- 120
ggplot(data=tweets, aes(x=created)) +
geom_bar(aes(fill=..count..), binwidth=60*minutes) +
scale_x_datetime("Date") +
scale_y_continuous("Frequency") +
#opts(title="#Superclásico Tweet Frequency April 1-5", legend.position='none')
ggsave(file='ismb-frequency.png', width=7, height=7, dpi=100)
library(tm)
library(twitteR)
# Twitter credentials
consumer_key <- "sjqXRKHfR2rD5VSPlYyscGTv1"
consumer_secret <- "fwB8pwlkc9K1YnrdKHt7pyZN0WzgsHiAoKUJJ9VpxCsoLKilWe"
access_token <- "1493511710-wmaNFnHNyn2FbutPkHCCwq61XOqYyuO7ODh4nsf"
access_secret <- "hpV8u6PCmH2eJUPbkUnKHPjgvTtPb5FnfUal64AM9phuR"
# Connect Twitter account
sig <- twitteR::setup_twitter_oauth(consumer_key , consumer_secret, access_token, access_secret)
folder<-"SuperClasico.Rdata.gz"
if(!file.exists(folder)){
# get 500 tweets with the hashtag #SuperClasico
SuperClasico <- searchTwitter("#SuperClasico", n = 500 ,since = '2016-04-02 00:00', until = '2016-04-03 00:00')
save(SuperClasico, file=folder, compress=TRUE)
} else{
load(folder)
}
head(SuperClasico)
# Get the Date
dateAPI <- date()
dateAPI
